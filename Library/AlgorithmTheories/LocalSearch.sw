(*

        Algorithm Theory for Local Search algorithms

The specification starts by importing basic problem theory DRO,
which characterizes problems in terms of
   D - input type, the given data
   R - output type, the results
   O - satisfaction predicate, which decides when an output z:R is
   feasible (acceptable) with respect to input instance x:D.

Interpreting these symbols into a problem domain gives us enough
information to specify a problem-solver:

  op f(x:D):{z:R | O(x,z)}

although this function spec is not part of DRO itself.  DRO is so
simple as to seem vacuous, but it allows us to specify abstract
algorithms, such as generate-and-test, that solve a given problem
without concern for the details of a concrete problem.

Local Search (LS) is a refinement of generate-and-test in that it
(implicitly) defines a generator of the output type in terms of a
discrete connected topology on the output type.  Typically, the
topology is a binary graph and elements of the output type are
generated by walking the graph from a start node.  The key assumption
is that the graph is fully connected.

More generally, we treat LS as the assumption of a relation on R.  In
hillclimbing LS algorithms, the relation is over RxR and is symmetric
to define the undirected graph topology.  The arcs of the graph define
the {\em neighborhood} of a node as the nodes that are adjacent, or
one step away.  Typically, the neighbors of a node n are constructed
by alternative simple structural modifications of n; e.g. if n is a
bitvector, then each neighbor differs from n in the value of exactly
one bit.

The assumed relation may be even richer if we use a hypergraph
topology.  For example, genetic algorithms can be specified in terms
of hyper-arcs, which model a crossover operation that connects a pair
of nodes with another pair of nodes.

In the LS theory below we specify the usual graph topology.  We
specify the connectedness assumption in terms of reachability of all
of R from any initial node.  The characteristic operation of a LS
algorithm is the neighboorhood generator that lists the neighborhood
of a given node.

Local Search structure is too weak to prove total correctness for
feasibility or optimization problems on infinite domains.  In LS
theory below, we assume a finite domain to provide a correctness
proof.

Optimization and Approximation variants of LS

For a real-world problem where the domain is infinite, LS is often
applied to a finite approximation, where the output domain is a finite
subset of the real-world domain.  Using a greedy control strategy that
hillclimbs (follows the steepest gradient locally) leads to
approximately optimal solutions for NP-hard optimization problems, but
usually without guarantees as to quality.  Using a Markov-Chain
Monte-Carlo (MCMC) control strategy provides probabilistic guarantees
of convergence in the limit when applied to such optimization
problems.  Simulated Annealing is based on a staged set of MCMC
formulations that improves the convergence rate.

Examples of Local Search algorithms:
1. bubblesort, shell sort
2. Simplex algorithm and refinements
3. hillclimbing, steepest ascent/descent
4. MCMC and simulated annealing for combinatorial optimization
5. genetic algorithms

*)

LocalSearchTheory = spec
  import ProblemTheory#DRO
  type State
  op InitialState : D -> State
  op NextState(x:D, st0:State): Option State
  op Extract : State -> R             % extract an R value from state

  (* defines the set of adjacent states *)
  type NeighborInfo    % represents structural change info
  op Neighbors : State -> List NeighborInfo
  op GenerateNeighbor : State * NeighborInfo -> State
  op Neighborhood(st:State): List State =
    map (fn(si)-> GenerateNeighbor(st,si)) (Neighbors st)

  (* ghost fn to test for a walk over the local search space .. *)
  op walk?(ss: List State): Boolean =
    if length ss <= 1
      then true
      else (let hd:State = head ss in
            let tl:List State = tail ss in
            (head tl in? Neighborhood hd) && walk?(tl))

  (*  All elements of R are reachable from the initial state via a finite walk *)
  axiom reachable_R_via_walk is
     fa(x:D,z:R)
     ex(k:Nat, ss: List State)
     length ss = k
     && head ss = InitialState x
     && Extract (last ss) = z
     && walk?(ss)

(* Missing text: A def of NextState such that we can prove finite
reachability of all elements of R.  This would be by iterated
generation of neighborhoods of InitialState.  It is not here since it
is clumsy to write and not needed by the algorithm.  It only serves to
verify the refinement relation from GenerateAndTest.   *)

 end-spec

(* We don't supply an algorithm schema/pattern for LS theory at this
level since it would require a complete enumeration of the output type
(as in G&T) in order to be able to prove correctness.  Instead we
develop refinements of LocalSearchTheory below that have more
structure that enables a provably correct schema. *)


(* ==================================================================
             Local Search for optimization problems

TODO: develop a theory of convex local search spaces that refines
LS_Unimodal_Theory

*)


LocalSearchOptTheory = spec
  import LocalSearchTheory, ProblemTheory#DROOpt
 end-spec

(* A graph (discrete topology) with costs at nodes is unimodal if
      there exists a node zhat (the mode or peak) such that for all
      nodes z there exists a walk from z to zhat that is monotone
      nondecreasing in cost.
*)

LS_Unimodal_Theory = spec
  import LocalSearchOptTheory

  op nodeCosts(x:D, walk: List State): List Nat =
    (case walk of
     | Nil -> Nil
     | st::w -> Cons(cost(x,Extract st),nodeCosts(x,w)))

  axiom State_Space_is_Unimodal is
    fa(x:D) ex(st0:State) fa(st:State) ex(walk: List State, costs: List Nat)
    walk?(walk)
    && costs = nodeCosts(x,walk)
    && st  = head walk
    && st0 = last walk
    && (fa(i:Int) i < (length costs) - 1
           => ((costs @ i) <= (costs @ succ(i))))

end-spec


(*****************   LS Optimization Scheme   ***********************

Instances: optimization of a unimodal unary function, Simplex algorithm.

TODO:  develop MCMC algorithm strategy which converges in the limit.

*)

LocalSearchOpt_SteepestGradient = spec
  import LS_Unimodal_Theory

(* This is a GT_opt instance: generate the neighborhood (elements of
     ns) and find the neighbor whose cost improves that of the current
     state st, if one exists.
   loosely
   D         +-> List State
   R         +-> {st':State | st' in? Neighbors st}
   O         +-> fn(x,st)->
   State     +-> List State | nonempty
   NextState +-> tail
   Extract   +-> Id
*)

  op NextState(x:D,st:State):
    {next: Option State
    | (case next of
       | None -> fa(st') st' in? Neighborhood st
                         => cost(x,Extract st) < cost(x,Extract st')
       | Some st' -> st' in? Neighborhood st
                     && (fa(st1:State) st1 in? Neighborhood st
                         => cost(x,Extract st') <= cost(x,Extract st1)))} =
    let ns:List State = Neighborhood st in
    if cost(x, Extract(head ns)) < cost(x,Extract st)
      then bestNeighbor(x, ns, Some (head ns), cost(x, Extract(head ns)))
      else bestNeighbor(x, ns, None, cost(x, Extract st))

  def bestNeighbor(x:D, ns:List State,
                   currentBestState:Option State,
                   currentBestCost:Nat) : Option State =
     let   st':State = head ns in   % extracted element
     let cost':Nat = cost(x,Extract st') in
     if cost'<currentBestCost
       then (case ns of
               | Nil   -> Some st'
               | _::tl -> bestNeighbor(x, tl, Some st', cost'))
       else (case ns of
               | Nil   -> currentBestState
               | _::tl -> bestNeighbor(x, tl, currentBestState, currentBestCost))

  def f(x:D): Option R =
    let init:State = InitialState x in
    LS_opt(x, init, Extract init)

  def LS_opt(x:D, st:State, currentBest:R) : Option R =
    let z:R = Extract st in
    let nextBest:R = (if O(x,z) && cost(x,z) < cost(x,currentBest)
                        then z
                      else currentBest) in
    case NextState(x,st) of
      | None     -> Some nextBest          %% success
      | Some st' -> LS_opt(x, st', nextBest)

  theorem correctness_of_LS_opt is
   fa(x:D) (case f(x) of
              | Some z -> O(x,z)
                          && (fa(x1:D,z1:R) O(x1,z1) => cost(x,z)<=cost(x1,z1))
              | None -> ~(ex(z)O(x,z)))
end-spec
